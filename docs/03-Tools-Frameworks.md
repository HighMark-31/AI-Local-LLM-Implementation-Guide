# ðŸš€ðŸ‘· Tools & Frameworks

## Major LLM Tools Comparison

### Ollama
**Best For**: Quick local setup, beginner-friendly

**Pros**:
- Simple one-command installation
- Pre-optimized models
- Great for macOS/Linux
- Streaming support

**Cons**:
- Limited customization
- Slower than native implementations

**Install**: `curl https://ollama.ai/install.sh | sh`

### LM Studio
**Best For**: Visual interface, Windows users

**Pros**:
- User-friendly GUI
- Easy model management
- Built-in chat interface
- No command line needed

**Cons**:
- GUI overhead
- Limited API exposure

### vLLM
**Best For**: Production deployments, high throughput

**Pros**:
- Extremely fast inference
- Advanced batching
- REST API support
- Optimized memory usage

**Cons**:
- Steeper learning curve
- GPU-only

### llama.cpp
**Best For**: Edge devices, CPU inference

**Pros**:
- C++ implementation (very fast)
- CPU-friendly
- Minimal dependencies
- Excellent for Raspberry Pi

**Cons**:
- CLI-only
- Limited ecosystem

## Model Repositories

### HuggingFace Hub
- 500,000+ models
- Community-driven
- Easy fine-tuning
- https://huggingface.co/models

### GGUF Models
- Optimized quantized versions
- TheBloke's collection (best resource)
- Direct download available

---

**Next**: [Setup & Installation](04-Setup-Installation.md)
